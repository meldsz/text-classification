{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP47670 - Assignment 2 - Text Classification\n",
    "**Student Name: Meleesha Mayola Dsouza, Nikil Mohan**<br>\n",
    "**Student Number: 18200024, 18200037**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.metrics import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Selecting the review categories and scraping the data from the website\n",
    "\n",
    "We will be performing the following steps under Task 1:<br/>\n",
    "Step 1: Choosing the review categories. We have chosen the following \n",
    "    <br/>&emsp;&emsp;&emsp;&emsp;_Health and Medical_\n",
    "    <br/>&emsp;&emsp;&emsp;&emsp;_Automotive_<br/>\n",
    "Step 2: Scraping the user reviews from the websites using the python package Beautiful Soup<br/>\n",
    "Step 3: Assigning class labels as 'positive' or 'negative' based on the user provided star ratings<br/>\n",
    "Step 4: Storing the user reviews in separate csv files for different review categories<br/>\n",
    "Step 5: Importing from the csv files to dataframe for easy data science manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For specifying the website, we append the individual webpages to the base website URL\n",
    "endpoint = 'http://mlg.ucd.ie/modules/yalp/'\n",
    "# The categories chosen have been represented in the form of a list\n",
    "categories = ['health_medical_list', 'automotive_list.html']\n",
    "\n",
    "# The extract_page function is created to extract the overall data present in the webpage\n",
    "def extract_page(url):\n",
    "    response = requests.get(url)\n",
    "    data = response.text\n",
    "    # We use the BeautifulSoup package to parse the data that is collected for webscraping\n",
    "    soup = BeautifulSoup(data,'html.parser')\n",
    "    return soup\n",
    "\n",
    "# The extract_reviews function is created to extract the reviews from the webpoge\n",
    "def extract_reviews(url):\n",
    "    soup = extract_page(url)\n",
    "    # We use the 'div' as the identifier as all the reviews are present within this tag\n",
    "    reviews_block = soup.findAll(\"div\", { \"class\" : \"review\" })\n",
    "    # We create a list called review_list to store all the reviews that are present in the category\n",
    "    review_list =[]\n",
    "    for reviews in reviews_block:\n",
    "        review = {}\n",
    "        # We use the 'img' as the identifier as all the ratings are present within this tag\n",
    "        star = reviews.find('img')\n",
    "        review[\"comments\"] = reviews.find(\"p\", { \"class\" : \"text\" }).get_text()\n",
    "        # We use the 'alt' attribute as the identifier as the rating present in this attribute can be easily obtained\n",
    "        # We use the concept of any rating having a value of 4 or 5 as Positive\n",
    "        # We use the concept of any rating having a value of 1, 2 or 3 as Negative\n",
    "        review[\"rating\"] = 'positive' if int(star.get('alt').split('-')[0]) >= 4 else 'negative'\n",
    "        review_list.append(review)        \n",
    "    return review_list\n",
    "\n",
    "# The extract_data function is created to extract the data from each of the review links\n",
    "# This function in turn calls the extract_page and the extract_reviews\n",
    "def extract_data(url):\n",
    "    soup = extract_page(url)\n",
    "    links = soup.find_all('a')\n",
    "    review_list =[]\n",
    "    for link in links:\n",
    "        # We identify the links of each of the reviews by extracting the values present in the href attribute\n",
    "        url = endpoint + link.get('href')\n",
    "        review = extract_reviews(url)\n",
    "        # We concatenate the reviews from all the links\n",
    "        review_list = review_list+review\n",
    "    return review_list\n",
    "\n",
    "# The create_database function is created to write the reviews and ratings to csv files for easier processing\n",
    "# The function will be called each time for each category\n",
    "def create_database(category_name, reviews):\n",
    "    header = reviews[0].keys()\n",
    "    with open(category_name, 'w',newline='', encoding=\"utf-8\") as output_file:\n",
    "        dict_writer = csv.DictWriter(output_file, header)\n",
    "        dict_writer.writeheader()\n",
    "        dict_writer.writerows(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a database for Health and Medical reviews so that we can process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We access the page for the reviews of the category 'Health and Medical'\n",
    "# We scrape the data using the functions defined by us\n",
    "# This data is stored in separate files in the csv format\n",
    "url = endpoint + categories[0]\n",
    "review_list = extract_data(url)\n",
    "create_database('Health_Medical.csv', review_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a database for Automotive reviews so that we can process them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We access the page for the reviews of the category 'Automotive'\n",
    "# We scrape the data using the functions defined by us\n",
    "# This data is stored in separate files in the csv format\n",
    "url = endpoint + categories[1]\n",
    "review_list = extract_data(url)\n",
    "create_database('Automotive.csv', review_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the Health and Medical dataset: (1450, 2)\n",
      "\n",
      "\n",
      "rating\n",
      "negative     407\n",
      "positive    1043\n",
      "Name: rating, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have so many good things to say about this p...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I found them to be highly skilled and an exper...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Where do I even begin? This office has been so...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I went in because I had toothache and needed a...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Found a new dental office. This place is amazi...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments    rating\n",
       "0  I have so many good things to say about this p...  positive\n",
       "1  I found them to be highly skilled and an exper...  positive\n",
       "2  Where do I even begin? This office has been so...  positive\n",
       "3  I went in because I had toothache and needed a...  positive\n",
       "4  Found a new dental office. This place is amazi...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dataframe dataset_A has the data obtained from csv containing Health and Medical reviews\n",
    "dataset_A = pd.read_csv('Health_Medical.csv')\n",
    "# We check the dimensions of the Health and Medical review data that we have\n",
    "print('Dimensions of the Health and Medical dataset: '+str(dataset_A.shape))\n",
    "print('\\n')\n",
    "# We also check the count of reviews in the Health and Medical dataset for each label, i.e. postive or negative\n",
    "print(dataset_A.groupby('rating')['rating'].count())\n",
    "# A preview of the data is shown\n",
    "dataset_A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the Automotive dataset: (1455, 2)\n",
      "\n",
      "\n",
      "rating\n",
      "negative    482\n",
      "positive    973\n",
      "Name: rating, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I arrived at 3 PM and the dealership closed at...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I dropped my car off on a Wednesday morning fo...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My parents have been buying cars off of Donna ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I recently bought another car from Donna Dunni...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I had to schedule an appointment due to the ai...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments    rating\n",
       "0  I arrived at 3 PM and the dealership closed at...  positive\n",
       "1  I dropped my car off on a Wednesday morning fo...  negative\n",
       "2  My parents have been buying cars off of Donna ...  positive\n",
       "3  I recently bought another car from Donna Dunni...  positive\n",
       "4  I had to schedule an appointment due to the ai...  positive"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The dataframe dataset_B has the data obtained from csv containing Automotive reviews\n",
    "dataset_B = pd.read_csv('Automotive.csv')\n",
    "# We check the dimensions of the Automotive review data that we have\n",
    "print('Dimensions of the Automotive dataset: '+str(dataset_B.shape))\n",
    "print('\\n')\n",
    "# We also check the count of reviews in the Automotive dataset for each label, i.e. postive or negative\n",
    "print(dataset_B.groupby('rating')['rating'].count())\n",
    "# A preview of the data is shown\n",
    "dataset_B.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Applying the pre-processing steps and building the classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform the preprocessing steps, we have used nltk packages. Some of the preprocessing steps done are as follows\n",
    "<br/>&emsp;&emsp;&emsp;&emsp;Tokenization\n",
    "<br/>&emsp;&emsp;&emsp;&emsp;Removal of punctuations\n",
    "<br/>&emsp;&emsp;&emsp;&emsp;Conversion to lower case\n",
    "<br/>&emsp;&emsp;&emsp;&emsp;Removal of stop words\n",
    "<br/><br/>\n",
    "\n",
    "We then use this preprocessed data to build the classifier models. We build a different classifier for each category of reviews to classify the positive and negative reviews. After building this classifier, we use an evaluation stategy to test the predictions for each of the classifiers. The evaluation strategy used in this assignment is the 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The preprocess_text function is called to handle the preprocessing steps for each review individually\n",
    "def preprocess_text(text):\n",
    "    # The data that is passed as the input is first converted to lowercase to standardize it\n",
    "    # We then tokenize this data into individual tokens\n",
    "    tokenized_words = word_tokenize(text.lower())\n",
    "    # We remove the words which are not alpha-numeric like punctuations\n",
    "    normalised_words = [word for word in tokenized_words if word.isalnum()]\n",
    "    # We remove the stopwords in the corpus like 'is', 'an', etc. as they do not contribute to the efficiency of the classifier\n",
    "    return ' '.join([word for word in normalised_words if word.lower() not in stopwords.words('english')])\n",
    "\n",
    "# The preprocess_reviews function is used to handle the pre-processing of all the reviews in the webpage\n",
    "# In turn, it calls the preprocess_text function to pre-process the reviews one by one\n",
    "def preprocess_reviews(dataset):\n",
    "    for indx, comments in enumerate(dataset['comments']):\n",
    "        dataset['comments'][indx] = preprocess_text(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>many good things say place needed cleaning fil...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>found highly skilled experienced dentistry wil...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>even begin office incredibly good family love ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>went toothache needed cleaning really friendly...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>found new dental office place amazing people w...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments    rating\n",
       "0  many good things say place needed cleaning fil...  positive\n",
       "1  found highly skilled experienced dentistry wil...  positive\n",
       "2  even begin office incredibly good family love ...  positive\n",
       "3  went toothache needed cleaning really friendly...  positive\n",
       "4  found new dental office place amazing people w...  positive"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We perform all the preprocessing steps on the reviews of the Health and Medical reviews\n",
    "preprocess_reviews(dataset_A)\n",
    "# We have displayed a few of the entries to show the difference between the data after preprocessing\n",
    "# The data before preprocessing for the Health and Medical datatset has already been displayed previously\n",
    "dataset_A.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>arrived 3 pm dealership closed 6 thought left ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dropped car wednesday morning diagnostic john ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>parents buying cars donna dunnivan decade alwa...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recently bought another car donna dunnivan 1 c...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>schedule appointment due airbag recall used we...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comments    rating\n",
       "0  arrived 3 pm dealership closed 6 thought left ...  positive\n",
       "1  dropped car wednesday morning diagnostic john ...  negative\n",
       "2  parents buying cars donna dunnivan decade alwa...  positive\n",
       "3  recently bought another car donna dunnivan 1 c...  positive\n",
       "4  schedule appointment due airbag recall used we...  positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We perform all the preprocessing steps on the reviews of the Automotive reviews\n",
    "preprocess_reviews(dataset_B)\n",
    "# We have displayed a few of the entries to show the difference between the data after preprocessing\n",
    "# The data before preprocessing for the Automotive dataset has already been displayed previously\n",
    "dataset_B.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the dataset as a preprocessing step to build the classifier\n",
    "\n",
    "We first merge the data from the dataset of two categrories so that we can apply the feature engineering steps required to process the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2905, 12377)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging the two datasets to form a unified dataset\n",
    "merged_dataset = pd.concat([dataset_A,dataset_B])\n",
    "# Numeric representation of the dataset using tfidf vector\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_merged = tfidf_vectorizer.fit_transform(merged_dataset['comments'])\n",
    "# We set the target value for the classifier\n",
    "y_merged = merged_dataset['rating']\n",
    "X_merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1450\n",
      "1455\n"
     ]
    }
   ],
   "source": [
    "X_reviewSize_A=dataset_A.shape[0]\n",
    "X_reviewSize_B=dataset_B.shape[0]\n",
    "# Identifying the boundary of each review category to help split later\n",
    "print(X_reviewSize_A)\n",
    "print(X_reviewSize_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now split the data to the values corresponding to its review categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1450, 12377)\n",
      "(1455, 12377)\n"
     ]
    }
   ],
   "source": [
    "X_A = X_merged[:X_reviewSize_A]\n",
    "target_A = y_merged[:X_reviewSize_A]\n",
    "X_B = X_merged[X_reviewSize_A:]\n",
    "target_B = y_merged[X_reviewSize_A:]\n",
    "# Identifying the dimensions of the separated datasets\n",
    "print(X_A.shape)\n",
    "print(X_B.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the classifier for the Health and Medical Review data\n",
    "\n",
    "We first apply standard text pre-processing steps to generate the document-term matrix for the reviews of Health and Medical category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set for Health and Medical reviews has 1015 examples\n",
      "The test set for Health and Medical reviews has 435 examples\n"
     ]
    }
   ],
   "source": [
    "# We partition the data to use for the classifier. We use a split of 70% training and 30% test data\n",
    "data_A_train, data_A_test, target_A_train, target_A_test = train_test_split(X_A, target_A, test_size=0.3)\n",
    "print(\"The training set for Health and Medical reviews has %d examples\" % data_A_train.shape[0] )\n",
    "print(\"The test set for Health and Medical reviews has %d examples\" % data_A_test.shape[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenting with the Logistic Regression classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# For the purpose of classification for the Health and Medical reviews, we experiment using Logistic Regression\n",
    "model_A_logreg = linear_model.LogisticRegression(solver='liblinear')\n",
    "model_A_logreg.fit(data_A_train, target_A_train)\n",
    "print(model_A_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[213  21]\n",
      " [ 30 165]]\n"
     ]
    }
   ],
   "source": [
    "# After training the model, we perform the actual prediction\n",
    "predicted_A_logreg = model_A_logreg.predict(data_A_test)\n",
    "# We build a confusion matrix so that we can see the classifiers performancee\n",
    "cm_A_logreg = confusion_matrix(target_A_test, predicted_A_logreg,labels=['positive','negative'])\n",
    "print(cm_A_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic Regression classifier = 0.88\n",
      "Precision (Positive) = 0.88\n",
      "Recall (Positive) = 0.91\n",
      "F1 (Positive) = 0.89\n"
     ]
    }
   ],
   "source": [
    "# We use metrics to check the performance of the Logistic regression clasifier on the Health and Medical review data\n",
    "CategoryA_accuracy_LogReg = accuracy_score(target_A_test, predicted_A_logreg)\n",
    "print(\"Accuracy of the Logistic Regression classifier = %.2f\" % CategoryA_accuracy_LogReg )\n",
    "# We indicate that we are interested in the Positive class here, which is labelled as \"positive\"\n",
    "print(\"Precision (Positive) = %.2f\" % precision_score(target_A_test, predicted_A_logreg, pos_label='positive') )\n",
    "print(\"Recall (Positive) = %.2f\" % recall_score(target_A_test, predicted_A_logreg, pos_label='positive') )\n",
    "print(\"F1 (Positive) = %.2f\" % f1_score(target_A_test, predicted_A_logreg, pos_label='positive') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.89      0.85      0.87       195\n",
      "   positive       0.88      0.91      0.89       234\n",
      "\n",
      "avg / total       0.88      0.88      0.88       429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A summary of the statisitcs is generated using scikit-learn's built in methods\n",
    "print(classification_report(target_A_test, predicted_A_logreg, target_names=[\"negative\",\"positive\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better evaluation mechanism would be to use the k-fold cross-validation approach. In the standard split, we are ignoring a part of the dataset. In this cross validation process, every portion of the data has the ability to be part of the training set at one point. Below, we have used a 10-fold cross validation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression classifier for Health and Medical reviews: Mean cross-validation accuracy = 0.87\n"
     ]
    }
   ],
   "source": [
    "# Cross validation using 10 fold for the Logistic Regression approach used for classifying Health and Medical reviews\n",
    "acc_scores_A_logreg =  cross_val_score(model_A_logreg, X_A, target_A, cv=10, scoring=\"accuracy\")\n",
    "print(\"Logistic Regression classifier for Health and Medical reviews: Mean cross-validation accuracy = %.2f\" % acc_scores_A_logreg.mean() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experimenting with the Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    }
   ],
   "source": [
    "# For the purpose of classification for the Health and Medical reviews, we experiment using Naive Bayes\n",
    "model_A_nb = MultinomialNB().fit(data_A_train, target_A_train)\n",
    "print(model_A_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[222  12]\n",
      " [ 62 133]]\n"
     ]
    }
   ],
   "source": [
    "# After training the model, we perform the actual prediction\n",
    "predicted_A_nb = model_A_nb.predict(data_A_test)\n",
    "# We build a confusion matrix so that we can see the classifiers performancee\n",
    "cm_A_nb = confusion_matrix(target_A_test, predicted_A_nb,labels=['positive','negative'])\n",
    "print(cm_A_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Naive Bayes classifier = 0.83\n",
      "Precision (Positive) = 0.78\n",
      "Recall (Positive) = 0.95\n",
      "F1 (Positive) = 0.86\n"
     ]
    }
   ],
   "source": [
    "# We use metrics to check the performance of the Naive Bayes clasifier on the Health and Medical review data\n",
    "CategoryA_accuracy_nb = accuracy_score(target_A_test, predicted_A_nb)\n",
    "print(\"Accuracy of the Naive Bayes classifier = %.2f\" % CategoryA_accuracy_nb )\n",
    "# We indicate that we are interested in the Positive class here, which is labelled as \"positive\"\n",
    "print(\"Precision (Positive) = %.2f\" % precision_score(target_A_test, predicted_A_nb, pos_label='positive') )\n",
    "print(\"Recall (Positive) = %.2f\" % recall_score(target_A_test, predicted_A_nb, pos_label='positive') )\n",
    "print(\"F1 (Positive) = %.2f\" % f1_score(target_A_test, predicted_A_nb, pos_label='positive') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   negative       0.92      0.68      0.78       195\n",
      "   positive       0.78      0.95      0.86       234\n",
      "\n",
      "avg / total       0.84      0.83      0.82       429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# A summary of the statisitcs is generated using scikit-learn's built in methods\n",
    "print(classification_report(target_A_test, predicted_A_nb, target_names=[\"negative\",\"positive\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better evaluation mechanism would be to use the k-fold cross-validation approach. In the standard split, we are ignoring a part of the dataset. In this cross validation process, every portion of the data has the ability to be part of the training set at one point. Below, we have used a 10-fold cross validation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes classifier for Health and Medical reviews: Mean cross-validation accuracy = 0.85\n"
     ]
    }
   ],
   "source": [
    "# Cross validation using 10 fold for the Naive Bayes approach used for classifying Health and Medical reviews\n",
    "acc_scores_A_nb =  cross_val_score(model_A_nb, X_A, target_A, cv=10, scoring=\"accuracy\")\n",
    "print(\"Naive Bayes classifier for Health and Medical reviews: Mean cross-validation accuracy = %.2f\" % acc_scores_A_nb.mean() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the experiments performed on the Health and Medical review data, we can see that the Logistic Regression and Naive Bayes classifier produces similar results.\n",
    "Due to the slight increase in accuracy of the Logistic Regression Model, we choose this model for evaluating it in task 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the classifier for the Automotive Review data\n",
    "\n",
    "We apply standard text pre-processing steps to generate the document-term matrix for the reviews of Automotive category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set for Automotive reviews has 1018 examples\n",
      "The test set for Automotive reviews has 437 examples\n"
     ]
    }
   ],
   "source": [
    "# We partition the data to use for the classifier. We use a split of 70% training and 30% test data\n",
    "data_B_train, data_B_test, target_B_train, target_B_test = train_test_split(X_B, target_B, test_size=0.3)\n",
    "print(\"The training set for Automotive reviews has %d examples\" % data_B_train.shape[0] )\n",
    "print(\"The test set for Automotive reviews has %d examples\" % data_B_test.shape[0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Experimenting with the K-Nearest Neighbor (KNN) classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=3, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "# For the purpose of classification for the Automotive reviews, we use KNN where n=3\n",
    "model_B_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "model_B_knn.fit(data_B_train, target_B_train)\n",
    "print(model_B_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[218  76]\n",
      " [ 33 110]]\n"
     ]
    }
   ],
   "source": [
    "# After training the model, we perform the actual prediction\n",
    "predicted_B_knn = model_B_knn.predict(data_B_test)\n",
    "# We build a confusion matrix so that we can see the classifiers performancee\n",
    "cm_B_knn = confusion_matrix(target_B_test, predicted_B_knn,labels=['positive','negative'])\n",
    "print(cm_B_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the KNN classifier = 0.75\n",
      "Precision (Positive) = 0.87\n",
      "Recall (Positive) = 0.74\n",
      "F1 (Positive) = 0.80\n"
     ]
    }
   ],
   "source": [
    "# We use metrics to check the performance of the KNN clasifier on the Automotive review data\n",
    "CategoryB_accuracy_KNN = accuracy_score(target_B_test, predicted_B_knn)\n",
    "print(\"Accuracy of the KNN classifier = %.2f\" % CategoryB_accuracy_KNN )\n",
    "# We indicate that we are interested in the Positive class here, which is labelled as \"positive\"\n",
    "print(\"Precision (Positive) = %.2f\" % precision_score(target_B_test, predicted_B_knn, pos_label='positive') )\n",
    "print(\"Recall (Positive) = %.2f\" % recall_score(target_B_test, predicted_B_knn, pos_label='positive') )\n",
    "print(\"F1 (Positive) = %.2f\" % f1_score(target_B_test, predicted_B_knn, pos_label='positive') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better evaluation mechanism would be to use the k-fold cross-validation approach. In the standard split, we are ignoring a part of the dataset. In this cross validation process, every portion of the data has the ability to be part of the training set at one point. Below, we have used a 10-fold cross validation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN classifier for Automotive reviews: Mean cross-validation accuracy = 0.66\n"
     ]
    }
   ],
   "source": [
    "# Cross validation using 10 fold for the KNN approach used for classifying Automotive reviews\n",
    "acc_scores_B_knn =  cross_val_score(model_B_knn, X_B, target_B, cv=10, scoring=\"accuracy\")\n",
    "print(\"KNN classifier for Automotive reviews: Mean cross-validation accuracy = %.2f\" % acc_scores_B_knn.mean() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Experimenting with the Support Vector Machine (SVM) classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n"
     ]
    }
   ],
   "source": [
    "# For the purpose of classification for the Automotive reviews, we use SVC\n",
    "model_B_svc = SVC(gamma='auto',kernel='linear')\n",
    "model_B_svc.fit(data_B_train, target_B_train)\n",
    "print(model_B_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[276  18]\n",
      " [ 15 128]]\n"
     ]
    }
   ],
   "source": [
    "# After training the model, we perform the actual prediction\n",
    "predicted_B_svc = model_B_svc.predict(data_B_test)\n",
    "# We build a confusion matrix so that we can see the classifiers performancee\n",
    "cm_B_svc = confusion_matrix(target_B_test, predicted_B_svc,labels=['positive','negative'])\n",
    "print(cm_B_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the SVC classifier = 0.92\n",
      "Precision (Positive) = 0.95\n",
      "Recall (Positive) = 0.94\n",
      "F1 (Positive) = 0.94\n"
     ]
    }
   ],
   "source": [
    "# We use metrics to check the performance of the SVC clasifier on the Automotive review data\n",
    "CategoryB_accuracy_svc = accuracy_score(target_B_test, predicted_B_svc)\n",
    "print(\"Accuracy of the SVC classifier = %.2f\" % CategoryB_accuracy_svc )\n",
    "# We indicate that we are interested in the Positive class here, which is labelled as \"positive\"\n",
    "print(\"Precision (Positive) = %.2f\" % precision_score(target_B_test, predicted_B_svc, pos_label='positive') )\n",
    "print(\"Recall (Positive) = %.2f\" % recall_score(target_B_test, predicted_B_svc, pos_label='positive') )\n",
    "print(\"F1 (Positive) = %.2f\" % f1_score(target_B_test, predicted_B_svc, pos_label='positive') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better evaluation mechanism would be to use the k-fold cross-validation approach. In the standard split, we are ignoring a part of the dataset. In this cross validation process, every portion of the data has the ability to be part of the training set at one point. Below, we have used a 10-fold cross validation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC classifier for Automotive reviews: Mean cross-validation accuracy = 0.90\n"
     ]
    }
   ],
   "source": [
    "# Cross validation using 10 fold for the SVC approach used for classifying Automotive reviews\n",
    "acc_scores_B_svc =  cross_val_score(model_B_svc, X_B, target_B, cv=10, scoring=\"accuracy\")\n",
    "print(\"SVC classifier for Automotive reviews: Mean cross-validation accuracy = %.2f\" % acc_scores_B_svc.mean() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "From the experiments performed on the Automotive review data, we can see that the KNN and SVM classifier produced different results.\n",
    "Due to the slight increase in accuracy of the Logistic Regression Model, we choose this model for evaluating it in task 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion of results and evaluation strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Performance of classification models across categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will use the classification model trained on the training data from one category to test it with the test data from the same category, as well as, test it with the entire data from the other category.<br/>We have already trained two different classifiers on the two categories of reviews chosen. These two classifiers used in the previous task will be used to check the performance across categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Health and Medical review category, we chose Linear Regression Classifier with a train-test split of 30% as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the Logistic Regression classifier model on the test data of the Health and Medical Category, we have an accuracy of 0.86\n"
     ]
    }
   ],
   "source": [
    "print('Using the Logistic Regression classifier model on the test data of the Health and Medical Category, we have an accuracy of %.2f' % CategoryA_accuracy_LogReg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use this Logistic Regression classifier model to test the data of the Automotive review Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[964   9]\n",
      " [292 190]]\n"
     ]
    }
   ],
   "source": [
    "# After training the model on Health and Medical reviews, we perform the prediction on Automotive reviews\n",
    "Prediction_diff_LogReg = model_A.predict(X_B)\n",
    "# We build a confusion matrix so that we can see the classifiers performancee\n",
    "cm_diff_logreg = confusion_matrix(target_B, Prediction_diff_LogReg,labels=['positive','negative'])\n",
    "print(cm_diff_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic Regression classifier = 0.79\n",
      "Precision (Positive) = 0.77\n",
      "Recall (Positive) = 0.99\n",
      "F1 (Positive) = 0.86\n"
     ]
    }
   ],
   "source": [
    "# We use metrics to check the performance of the Logistic regression clasifier on the Automotive data\n",
    "accuracy_diff_LogReg = accuracy_score(target_B, Prediction_diff_LogReg)\n",
    "print(\"Accuracy of the Logistic Regression classifier = %.2f\" % accuracy_diff_LogReg )\n",
    "# We indicate that we are interested in the Positive class here, which is labelled as \"positive\"\n",
    "print(\"Precision (Positive) = %.2f\" % precision_score(target_B, Prediction_diff_LogReg, pos_label='positive') )\n",
    "print(\"Recall (Positive) = %.2f\" % recall_score(target_B, Prediction_diff_LogReg, pos_label='positive') )\n",
    "print(\"F1 (Positive) = %.2f\" % f1_score(target_B, Prediction_diff_LogReg, pos_label='positive') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Automotive review category, we chose KNN Classifier with K=3 and a train-test split of 30% as test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the KNN classifier model on the test data of the Automotive Category, we have an accuracy of 0.77\n"
     ]
    }
   ],
   "source": [
    "print('Using the KNN classifier model on the test data of the Automotive Category, we have an accuracy of %.2f' % CategoryB_accuracy_KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[941 102]\n",
      " [156 251]]\n"
     ]
    }
   ],
   "source": [
    "# After training the model on Autmotive reviews, we perform the actual prediction on the Health and Medical reviews\n",
    "Prediction_diff_knn = model_B.predict(X_A)\n",
    "# We build a confusion matrix so that we can see the classifiers performancee\n",
    "cm_diff_knn = confusion_matrix(target_A, Prediction_diff_knn,labels=['positive','negative'])\n",
    "print(cm_diff_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the KNN classifier = 0.82\n",
      "Precision (Positive) = 0.86\n",
      "Recall (Positive) = 0.90\n",
      "F1 (Positive) = 0.88\n"
     ]
    }
   ],
   "source": [
    "# We use metrics to check the performance of the KNN clasifier on the Health and Medical data\n",
    "accuracy_diff_knn = accuracy_score(target_A, Prediction_diff_knn)\n",
    "print(\"Accuracy of the KNN classifier = %.2f\" % accuracy_diff_knn )\n",
    "# We indicate that we are interested in the Positive class here, which is labelled as \"positive\"\n",
    "print(\"Precision (Positive) = %.2f\" % precision_score(target_A, Prediction_diff_knn, pos_label='positive') )\n",
    "print(\"Recall (Positive) = %.2f\" % recall_score(target_A, Prediction_diff_knn, pos_label='positive') )\n",
    "print(\"F1 (Positive) = %.2f\" % f1_score(target_A, Prediction_diff_knn, pos_label='positive') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary of all these results are as follows:<br/>\n",
    "Logistic regression was used to classsify the reviews in the Health and Medical reviews category.<br/>\n",
    "KNN with k=3 was used classify the reviews in the Automotive reviews category.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the classifier used was Logistic Regression,\n",
      " \n",
      "Accuracy when Training data and Test data are both on Health and Medical Review = 0.86\n",
      "\n",
      "Accuracy when Training data is Health and Medical review, but Test data is Automobile review= 0.79\n"
     ]
    }
   ],
   "source": [
    "print(\"When the classifier used was Logistic Regression,\")\n",
    "print(\" \\nAccuracy when Training data and Test data are both on Health and Medical Review = %.2f\" % CategoryA_accuracy_LogReg)\n",
    "print(\"\\nAccuracy when Training data is Health and Medical review, but Test data is Automobile review= %.2f\" % accuracy_diff_LogReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When the classifier used was K Nearest Neighbour\n",
      "\n",
      "Accuracy when Training data and Test data are both on Automotive Review = 0.77\n",
      "\n",
      "Accuracy when Training data is Automotive review, but Test data is Health and Medical review = 0.82\n"
     ]
    }
   ],
   "source": [
    "print(\"When the classifier used was K Nearest Neighbour\")\n",
    "print(\"\\nAccuracy when Training data and Test data are both on Automotive Review = %.2f\" % CategoryB_accuracy_KNN);\n",
    "print(\"\\nAccuracy when Training data is Automotive review, but Test data is Health and Medical review = %.2f\" % accuracy_diff_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy values of the classifiers are different but comparable when used on a category other than what it was trained on.<br/>This is because, each domain/category might have keywords that correspond to their domain/category alone. The classifier would not have identified these new keywords as an important factor in the classification as it still gives priority to the keywords it found in the category it was trained on.<br/>\n",
    "\n",
    "However, we also acknowledge that the classifier has shown a comparable accuracy with the data values for a different category, this could be because general words of praise/complaints are always similar no matter what category we choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
